{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a534b7c2",
   "metadata": {},
   "source": [
    "# LightGBM model training\n",
    "\n",
    "This notebook connects to the project Postgres database, pulls transactions, performs per-user feature engineering, trains a LightGBM model to predict a credit score (or proxy), and saves the model to `ml/model.lgb`.\n",
    "\n",
    "Notes:\n",
    "- If you have a ground-truth `score` column for each user in your DB, use that as the target.\n",
    "- Otherwise, this notebook demonstrates creating a proxy target for demonstration only. Replace with a real label for production training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defb8c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies in your environment before running: polars, psycopg2-binary, lightgbm, scikit-learn\n",
    "import os\n",
    "import polars as pl\n",
    "import psycopg2\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c2ba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB connection - ensure DATABASE_URL is set in your environment\n",
    "db_url = os.environ.get('DATABASE_URL')\n",
    "assert db_url, 'Set DATABASE_URL before running this notebook'\n",
    "conn = psycopg2.connect(db_url)\n",
    "cur = conn.cursor()\n",
    "# Pull transactions - adjust column names if your schema differs\n",
    "cur.execute('SELECT \n",
    ", date, description, amount, type FROM \n",
    " ORDER BY \"userId\", date ASC')\n",
    "rows = cur.fetchall()\n",
    "conn.close()\n",
    "df = pl.DataFrame(rows, schema=['userId','date','description','amount','type'])\n",
    "print('Total rows', df.height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea688886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering per user\n",
    "def compute_user_features(user_df: pl.DataFrame) -> dict:\n",
    "    # Very similar to the server feature logic in api/python/get_score.py\n",
    "    if user_df.height == 0:\n",
    "        return { 'avg_monthly_income':0, 'avg_monthly_expense':0, 'savings_rate':0, 'expense_to_income_ratio':0, 'num_loan_payments':0, 'pct_spend_on_food':0, 'total_transactions':0 }\n",
    "    if 'date' in user_df.columns:\n",
    "        user_df = user_df.with_column(pl.col('date').str.strptime(pl.Datetime, fmt=None).alias('date'))\n",
    "        user_df = user_df.with_column(pl.col('date').dt.strftime('%Y-%m').alias('month'))\n",
    "    else:\n",
    "        user_df = user_df.with_column(pl.lit('unknown').alias('month'))\n",
    "    # cast amount\n",
    "    user_df = user_df.with_column(pl.col('amount').cast(pl.Float64))\n",
    "    monthly = user_df.groupby(['month','type']).agg(pl.col('amount').sum().alias('sum_amount'))\n",
    "    try:\n",
    "        income = monthly.filter(pl.col('type') == 'Credit').select('sum_amount').to_series().to_list()\n",
    "        expense = monthly.filter(pl.col('type') == 'Debit').select('sum_amount').to_series().to_list()\n",
    "    except Exception:\n",
    "        income = []\n",
    "        expense = []\n",
    "    avg_income = float(sum(income)/len(income)) if income else 0\n",
    "    avg_expense = float(sum(expense)/len(expense)) if expense else 0\n",
    "    savings_rate = ((avg_income - avg_expense)/avg_income*100) if avg_income else 0\n",
    "    expense_to_income_ratio = (avg_expense/avg_income) if avg_income else 0\n",
    "    descs = [ (d or '').lower() for d in user_df.get_column('description').to_list() ]\n",
    "    loan_count = sum(1 for d in descs if any(k in d for k in ['emi','loan','instal']))\n",
    "    total_debit = sum(abs(x) for x,t in zip(user_df.get_column('amount').to_list(), user_df.get_column('type').to_list()) if t=='Debit')\n",
    "    food_spend = sum(abs(x) for x,t,d in zip(user_df.get_column('amount').to_list(), user_df.get_column('type').to_list(), descs) if t=='Debit' and any(k in d for k in ['zomato','swiggy','food','restaurant']))\n",
    "    pct_food = (food_spend/total_debit*100) if total_debit else 0\n",
    "    return {'avg_monthly_income':avg_income, 'avg_monthly_expense':avg_expense, 'savings_rate':savings_rate, 'expense_to_income_ratio':expense_to_income_ratio, 'num_loan_payments':loan_count, 'pct_spend_on_food':pct_food, 'total_transactions':user_df.height}\n",
    "\n",
    "# Build features for all users\n",
    "users = df.select('userId').unique().to_series().to_list()\n",
    "rows = []\n",
    "for u in users:\n",
    "    udf = df.filter(pl.col('userId') == u)\n",
    "    feats = compute_user_features(udf)\n",
    "    feats['userId']=u\n",
    "    rows.append(feats)\n",
    "fdf = pl.DataFrame(rows)\n",
    "print('Users:', fdf.height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a20000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data - replace `target` with real labels if available. Here we create a proxy target for demonstration.\n",
    "# Proxy: higher savings_rate and lower expense_to_income_ratio -> higher score\n",
    "import numpy as np\n",
    "fdf = fdf.with_column((50 + (fdf['savings_rate']*2) - (fdf['expense_to_income_ratio']*20)).alias('target_proxy'))\n",
    "X = fdf.select(['avg_monthly_income','avg_monthly_expense','savings_rate','expense_to_income_ratio','num_loan_payments','pct_spend_on_food','total_transactions']).to_pandas()\n",
    "y = fdf.select('target_proxy').to_series().to_list()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "valid_data = lgb.Dataset(X_test, label=y_test)\n",
    "params = { 'objective':'regression', 'metric':'rmse', 'verbosity':-1 }\n",
    "bst = lgb.train(params, train_data, valid_sets=[train_data, valid_data], num_boost_round=100, early_stopping_rounds=10)\n",
    "preds = bst.predict(X_test)\n",
    "print('RMSE', mean_squared_error(y_test, preds, squared=False))\n",
    "# Save model to ml/model.lgb\n",
    "os.makedirs('ml', exist_ok=True)\n",
    "bst.save_model('ml/model.lgb')\n",
    "print('Saved model to ml/model.lgb')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
